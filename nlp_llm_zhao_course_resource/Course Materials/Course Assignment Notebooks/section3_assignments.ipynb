{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d972dde1-0b3f-4ade-b6da-49058b216864",
   "metadata": {},
   "source": [
    "# Text Preprocessing Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcb0760-0f9f-4243-a03f-d11b1ae26d62",
   "metadata": {},
   "source": [
    "## 0. Create a New Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a06743-c055-42da-abb2-2f1c7aa9dcbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e62b33ab-bfb7-433b-8394-7589dea8eacb",
   "metadata": {},
   "source": [
    "## 1. Text Preprocessing with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa90ff53-dea4-4438-a113-cd2c3ed91a55",
   "metadata": {},
   "source": [
    "1. Read the _childrens_books.csv_ file into a Jupyter Notebook\n",
    "2. Within the Description column:\n",
    "* Make all the text lowercase\n",
    "* Remove all \\xa0 characters\n",
    "* Remove all punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c210240a-dd7f-46fb-b806-6d752fe3fc93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5035f78-c434-43b9-9679-f55d30d15d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbb7b60-431b-4cf0-bda7-6fca1f9b2ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43cac333-a01e-4dec-a2b8-bf130a1e9e99",
   "metadata": {},
   "source": [
    "## 2. Text Preprocessing with spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4664502-df12-4524-a91a-393c6775b8dd",
   "metadata": {},
   "source": [
    "In addition to the lowercasing and special character removal from the previous assignment, within the cleaned Description column:\n",
    "* Tokenize the text\n",
    "* Lemmatize the text\n",
    "* Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c3be64-1530-4338-917e-6b5ba0bd92bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7234286e-9a3f-405b-aa39-c3a21829a47f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edcb1a5-e81c-4e51-92ce-3f536ca72166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa7bd356-794c-42d3-96c6-3b5fc13d261a",
   "metadata": {},
   "source": [
    "## 3. Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5a8c9b-94f2-4070-b988-44f7f5c5e13b",
   "metadata": {},
   "source": [
    "1. Vectorize the cleaned and normalized text using Count Vectorizer with the default parameters\n",
    "2. Modify the Count Vectorizer parameters to reduce the number of columns:\n",
    "* Remove stop words\n",
    "* Set a minimum document frequency of 10%\n",
    "3. Use the updated Count Vectorizer to identify the:\n",
    "* Top 10 most common terms\n",
    "* Top 10 least common terms that appear in at least 10% of the documents\n",
    "4. Create a horizontal bar chart of the top 10 most common terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91d33a9-f9d0-4613-8714-7a0bdcb4ddae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9325bbe5-d7a4-4e79-ad40-2416baeed08a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8fb639-8b8c-4868-ab9e-4b7bcc36aaa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ff5d6e1-d4e4-42dc-bf62-e5bd638ef96a",
   "metadata": {},
   "source": [
    "## 4. TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee4772b-979a-4386-ae05-f279b432c4e5",
   "metadata": {},
   "source": [
    "1. Vectorize the cleaned and normalized text using TF-IDF Vectorizer with the default parameters\n",
    "2. Modify the TF-IDF Vectorizer parameters to reduce the number of columns:\n",
    "* Remove stop words\n",
    "* Set a minimum document frequency of 10%\n",
    "* Set a maximum document frequency of 50%\n",
    "3. Using the updated TF-IDF Vectorizer, create a  horizontal bar chart of the top 10 most highly weighted terms\n",
    "4. Compare the Count Vectorizer bar chart from the previous assignment with the TF-IDF Vectorizer bar chart and note the differences in the top term lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5abbcd-7698-4d79-9f22-3de97958954d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34ac3e1-fc4b-4e9f-a8f3-f85883e5eebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cfdc4c-d3f8-4bd7-bfb7-109345f995ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
